{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯\n",
    "\n",
    "如果两个变量x1,x2间相互独立，则有 p(x1) * p(x2) = p(x1,x2)\n",
    "\n",
    "同样，在y发生的条件下也成立，即 P(x1|y) * P(x2|y) = P(x1,x2|y)\n",
    "\n",
    "朴素贝叶斯的“朴素”一词的含义：各个特征变量之间是相互独立的\n",
    "\n",
    "先验概率: 就是我们直观所理解的概率 P(y)\n",
    "\n",
    "后验概率：指的是某一事件发生之后的概率 P(y|x1,x2)\n",
    "\n",
    "而我们要求的概率为 P(y|x1,x2)，可以通过贝叶斯公式转化成如下形式：\n",
    "\n",
    "P(y|x1,x2) = P(x1,x2|y) * P(y) / P(x1,x2) \n",
    "\n",
    "由于各个特征变量相互独立，所以可进一步转化成 P(y|x1,x2) = P(x1|y) * P(x2|y) * P(y) / (P(x1) * P(x2)) \n",
    "\n",
    "因此，可以看出，要想求得P(y|x1,x2),我们需要求得该类别下对应特征x1,x2的概率、该类别的概率、对应特征x1,x2的概率\n",
    "\n",
    "但对于一个已知feature的样本来说，不管求哪个类别的概率值,P(x1),P(x2)都是相同的，所以可以不用考虑！\n",
    "\n",
    "即 P(y|x1,x2) = P(x1|y) * P(x2|y) * P(y)\n",
    "\n",
    "以书本上的数据为例\n",
    "\n",
    "![avatar](img/naive_bayes_1.png)\n",
    "\n",
    "要求 P(y|x1=2,x2=S)，算出每个类别的概率值，然后取最大的那个类别\n",
    "\n",
    "当y = 1时，P(y=1|x1=2,x2=S) = P(x1=2|y=1) * P(x2=S|y=1) * P(y=1) / (P(x1=2) * P(x2=S)) = 3/9 * 1/9 * 9/15 /(5/15 * 4/15)  = 1/4\n",
    "\n",
    "当y = -1时,P(y=-1|x1=2,x2=S) = P(x1=2|y=-1) * P(x2=S|y=-1) * P(y=-1) / (P(x1=2) * P(x2=S)) = 2/6 * 3/6 * 6/15 /(5/15 * 4/15)  = 3/4\n",
    "\n",
    "由于P(x1),P(x2)都是一样的，所以可以忽略，就变成了书上的这种形式，因为我们的目标是找出概率最大的那个类，所以只需要考虑相对大小就行了！\n",
    "\n",
    "因此，就变成了下面这个公式\n",
    "\n",
    "![avatar](img/naive_bayes_2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现\n",
    "采取书上的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X0 X1  label\n",
       "0   1  S     -1\n",
       "1   1  M     -1\n",
       "2   1  M      1\n",
       "3   1  S      1\n",
       "4   1  S     -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 构造数据\n",
    "data = [[1,'S',-1],[1,'M',-1],[1,'M',1],[1,'S',1],[1,'S',-1],[2,'S',-1],[2,'M',-1],[2,'M',1],[2,'L',1],[2,'L',1],[3,'L',1],[3,'M',1],[3,'M',1],[3,'L',1],[3,'L',-1]]\n",
    "df = pd.DataFrame(data,columns=[\"X0\",\"X1\",\"label\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 朴素贝叶斯\n",
    "class NaiveBayes:\n",
    "    \n",
    "    def classfiy(self,df,target):\n",
    "        # 整个数据的长度\n",
    "        total_len = len(df)\n",
    "        # 存放不同种类的类别标签\n",
    "        label_list = []\n",
    "        # 只从df里取最后一列\n",
    "        for label in df.iloc[:,-1]:\n",
    "            # 如果没在label_list里则往里添加\n",
    "            if label not in label_list:\n",
    "                label_list.append(label)\n",
    "        # 概率最高的那个label\n",
    "        best_label = None\n",
    "        # 最高的概率值\n",
    "        best_prob = 0\n",
    "        # 遍历每个可能的label\n",
    "        for y_i in label_list:\n",
    "            '''\n",
    "            p_y : 先验概率 P(y)\n",
    "            p_y_x : 后验概率 P(y|x)\n",
    "            p_xi_y : 条件概率，P(xi|y)\n",
    "            P(y|x) = P(y) * P(x1|y) * P(x2|y) \n",
    "            '''\n",
    "            # 取出label相同的那些行构建一个新的df\n",
    "            df_yi = df.loc[df.get(df.columns[-1])==y_i]\n",
    "            # 先验概率 P(y)\n",
    "            p_y = len(df_yi)/total_len\n",
    "            print(\"计算P(y={})的概率:\".format(y_i),p_y)\n",
    "            # 后验概率 = 先验概率 * 各个feature的条件概率\n",
    "            p_y_x = p_y\n",
    "            # 计算每个 P(xi|y),index为feature的下标索引,xi为feature的名称\n",
    "            for index,xi in enumerate(df.columns[:-1]):\n",
    "                # 每个feature的P(xi|y)的条件概率\n",
    "                p_xi_y = len(df_yi.loc[df_yi.get(xi)==target[index]])/len(df_yi)\n",
    "                print(\"计算条件概率P(x{}={}|y={})的概率：\".format(index,target[index],y_i),p_xi_y)\n",
    "                p_y_x *= p_xi_y\n",
    "            # 预测类别为y_i的后验概率\n",
    "            print(\"label 为{}的概率\".format(y_i),p_y_x)\n",
    "            # 如果比先前的最大概率要大，更新最大概率和对应的标签类别\n",
    "            if p_y_x > best_prob:\n",
    "                best_prob = p_y_x\n",
    "                best_label = y_i\n",
    "            print(\"============\")\n",
    "        \n",
    "        return best_label\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    lamb : lambda,拉普拉斯平滑的参数\n",
    "    K 为这个随机变量中不同离散属性的个数，如在随机变量Y中k=2，因为只有1和-1两种，而在X0随机变量中K=3，因为有3种取值\n",
    "    Y=y的先验概率为 （Y=y的个数 + lambda）/ （样本个数 + K * labmda）\n",
    "    P(Y=y) = (N(Y=y) + labmda) / (N + k * lambda) \n",
    "    '''\n",
    "    def classfiy_with_laplace(self,df,target,lamb = 1):\n",
    "        # 整个数据的长度\n",
    "        total_len = len(df)\n",
    "        # 存放不同种类的类别标签\n",
    "        label_list = []\n",
    "        # 只从df里取最后一列\n",
    "        for label in df.iloc[:,-1]:\n",
    "            # 如果没在label_list里则往里添加\n",
    "            if label not in label_list:\n",
    "                label_list.append(label)\n",
    "        # 概率最高的那个label\n",
    "        best_label = None\n",
    "        # 最高的概率值\n",
    "        best_prob = 0\n",
    "        \n",
    "        # 加上拉普拉斯平滑，遍历每个可能的label\n",
    "        for y_i in label_list:\n",
    "            '''\n",
    "            p_y : 先验概率 P(y)\n",
    "            p_y_x : 后验概率 P(y|x)\n",
    "            p_xi_y : 条件概率，P(xi|y)\n",
    "            P(y|x) = P(y) * P(x1|y) * P(x2|y) \n",
    "            '''\n",
    "            # 取出label相同的那些行构建一个新的df\n",
    "            df_yi = df.loc[df.get(df.columns[-1])==y_i]\n",
    "            # 先验概率 P(y)\n",
    "            # unique 获得一个序列不同元素构成的集合，len取长度\n",
    "            p_y = (len(df_yi) + lamb)/(total_len + lamb * len(df.iloc[:,-1].unique()))\n",
    "            print(\"计算P(y={})的概率:\".format(y_i),p_y)\n",
    "            # 后验概率 = 先验概率 * 各个feature的条件概率\n",
    "            p_y_x = p_y\n",
    "            # 计算每个 P(xi|y),index为feature的下标索引,xi为feature的名称\n",
    "            for index,xi in enumerate(df.columns[:-1]):\n",
    "                # 每个feature的P(xi|y)的条件概率\n",
    "                p_xi_y = (len(df_yi.loc[df_yi.get(xi)==target[index]]) + lamb)/(len(df_yi) + lamb * len(df_yi.iloc[:,index].unique()))\n",
    "                print(\"计算条件概率P(x{}={}|y={})的概率：\".format(index,target[index],y_i),p_xi_y)\n",
    "                p_y_x *= p_xi_y\n",
    "            # 预测类别为y_i的后验概率\n",
    "            print(\"label 为{}的概率\".format(y_i),p_y_x)\n",
    "            # 如果比先前的最大概率要大，更新最大概率和对应的标签类别\n",
    "            if p_y_x > best_prob:\n",
    "                best_prob = p_y_x\n",
    "                best_label = y_i\n",
    "            print(\"============\")\n",
    "        \n",
    "        return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算P(y=-1)的概率: 0.4\n",
      "计算条件概率P(x0=2|y=-1)的概率： 0.3333333333333333\n",
      "计算条件概率P(x1=S|y=-1)的概率： 0.5\n",
      "label 为-1的概率 0.06666666666666667\n",
      "============\n",
      "计算P(y=1)的概率: 0.6\n",
      "计算条件概率P(x0=2|y=1)的概率： 0.3333333333333333\n",
      "计算条件概率P(x1=S|y=1)的概率： 0.1111111111111111\n",
      "label 为1的概率 0.02222222222222222\n",
      "============\n",
      "预测的类别标签： -1\n"
     ]
    }
   ],
   "source": [
    "# 朴素贝叶斯\n",
    "clf = NaiveBayes()\n",
    "target = [2,'S']\n",
    "res = clf.classfiy(df,target)\n",
    "print(\"预测的类别标签：\",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算P(y=-1)的概率: 0.4117647058823529\n",
      "计算条件概率P(x0=2|y=-1)的概率： 0.3333333333333333\n",
      "计算条件概率P(x1=S|y=-1)的概率： 0.4444444444444444\n",
      "label 为-1的概率 0.06100217864923746\n",
      "============\n",
      "计算P(y=1)的概率: 0.5882352941176471\n",
      "计算条件概率P(x0=2|y=1)的概率： 0.3333333333333333\n",
      "计算条件概率P(x1=S|y=1)的概率： 0.16666666666666666\n",
      "label 为1的概率 0.0326797385620915\n",
      "============\n",
      "预测的类别标签： -1\n"
     ]
    }
   ],
   "source": [
    "# 带拉普拉斯平滑的朴素贝叶斯\n",
    "clf = NaiveBayes()\n",
    "target = [2,'S']\n",
    "res = clf.classfiy_with_laplace(df,target)\n",
    "print(\"预测的类别标签：\",res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 那么问题来了！我们上述求的是针对离散变量的，如果是连续变量怎么办呢？\n",
    "\n",
    "对于连续变量，P(X=xi|y) = 0,按上述方法求肯定很多地方会出现0从而无法进行下去\n",
    "\n",
    "因此，引出了针对连续变量的朴素贝叶斯方法===>高斯朴素贝叶斯\n",
    "\n",
    "离散变量有概率分布，同样的，对于连续变量是概率分布函数，也就是密度函数，采用高斯分布（正态分布）\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "![avatar](naive_bayes_3.png)\n",
    "\n",
    "数学期望：在概率论和统计学中，数学期望(mean)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。\n",
    "\n",
    "标准差（StandardDeviation），在概率统计中最常使用作为统计分布程度（statisticaldispersion）上的测量。标准差定义是总体各单位标准值与其平均数离差平方的算术平均数的平方根。\n",
    "\n",
    "从给定的训练数据集中，可以计算出数学期望E（X）和标准差 σ (下面公式用S表示)\n",
    "\n",
    "$E(X)=\\sum{xp(x)}=\\mu$\n",
    "\n",
    "$S^2={\\sum (x_i-\\bar x)^2 \\over N}$\n",
    "\n",
    "$S=\\sqrt{\\sum (x_i-\\bar x)^2 \\over N}$\n",
    "\n",
    "将计算出的数学期望E（X）和标准差 σ 代入到高斯密度函数里即可拟合出数据分布,即可计算出当连续变量x=x0时的条件概率P(x=x0|y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB:\n",
    "    \n",
    "    # 计算一组数据的数学期望（均值）\n",
    "    def mean(self,X):\n",
    "        return sum(X)/len(X)\n",
    "    \n",
    "    # 计算一组数据的标准差\n",
    "    def stddev(self,X):\n",
    "        mean = self.mean(X)\n",
    "        ret = np.sqrt(sum((X-mean)**2)/len(X)) # N在这里更科学的说法是自由度，假设n为样本数， N = n-1，数据大的时候差不差1影响不大\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "    def fit(self,df):\n",
    "        label_list = []\n",
    "        for label in df.iloc[:,-1]:\n",
    "            if label not in label_list:\n",
    "                label_list.append(label)\n",
    "        self.label_list = label_list        \n",
    "        self.df = df\n",
    "        '''\n",
    "        P_prior：存储各个标签的先验概率P(y=yi)的字典 \n",
    "        '''\n",
    "        P_prior = {}\n",
    "        \n",
    "        '''\n",
    "        构建存储条件概率P(X = xi|Y = yi)的字典\n",
    "        形式为\n",
    "        {\n",
    "            \"yi\": {\n",
    "            \"x0\": \"P(x=x0|y=yi)的高斯分布参数(mean,stddev)\",\n",
    "            \"x1\": \"P(x=x1|y=yi)的高斯分布参数(mean,stddev)\"\n",
    "            ...\n",
    "            }\n",
    "            ...\n",
    "        }\n",
    "        '''\n",
    "        P_dic = {}\n",
    "        \n",
    "        # 对每个类别进行遍历计算各个feature的条件概率 P(x=xi|y_i)\n",
    "        for y_i in label_list:\n",
    "            # 构建y=yi的条件概率字典\n",
    "            yi_dic = {}\n",
    "            \n",
    "            # 去掉最后一列label\n",
    "            df_yi = df[df.get(df.columns[-1])==y_i]\n",
    "            df_yi = df_yi.iloc[:,:-1]\n",
    "            # 计算先验概率\n",
    "            P_prior[y_i] = len(df_yi)/len(df) \n",
    "            # 遍历每个feature\n",
    "            for index,feature_name in enumerate(df_yi.columns):\n",
    "                # 对应feature形成的一组序列(series)\n",
    "                data = df_yi.iloc[:,index]\n",
    "                # 求数学期望、标准差\n",
    "                mean = self.mean(data)\n",
    "                stddev = self.stddev(data)\n",
    "                yi_dic[feature_name] = (mean,stddev)\n",
    "                print(\"条件概率P(X = {}|y = {})的高斯分布密度函数的参数 u = {} , σ = {}\".format(feature_name,y_i,mean,stddev))\n",
    "            P_dic[y_i] = yi_dic\n",
    "    \n",
    "        self.P_prior = P_prior\n",
    "        self.P_dic = P_dic\n",
    "        \n",
    "    # 根据传进来的期望、标准差参数计算高斯分布在指定位置x0的条件概率值\n",
    "    def calc(self,mean,sigema,x0):\n",
    "        exponent = np.exp(-((x0-mean)**2/(2*sigema**2)))\n",
    "        ret = 1/(np.sqrt(2*math.pi)*sigema)*exponent\n",
    "        return ret\n",
    "        \n",
    "    def predict(self,target):\n",
    "        # best_prob表示最大概率，best_label表示最大概率对应的标签\n",
    "        best_label = None\n",
    "        best_prob = 0\n",
    "        # 计算每个类别的概率\n",
    "        print(\"===============准备计算各个类别的后验概率P(y=yi|X=xi)==============\")\n",
    "        print(\"\")\n",
    "        for y_i in self.label_list:\n",
    "            # P(X=x|y=yi) = P(y=yi) * P(x=x1|y=yi) * P(x=x2|y=yi)\n",
    "            cur_prob = self.P_prior[y_i]\n",
    "            print(\"先验概率P(y={}的值为{})\".format(y_i,cur_prob))\n",
    "            # 计算各个feature的条件概率\n",
    "            for index,feature in enumerate(self.df.columns[:-1]):\n",
    "                # 获取高斯分布的参数\n",
    "                u,sigema = self.P_dic.get(y_i).get(feature)\n",
    "                # 计算概率分布\n",
    "                P_cond = self.calc(u,sigema,target[index])\n",
    "                print(\"条件概率P(X = {}|y = {})的值为{}\".format(feature,y_i,P_cond))\n",
    "                cur_prob *= P_cond\n",
    "            print(\"类别标签为{}的概率值为{}\".format(y_i,cur_prob))\n",
    "            print(\"\")\n",
    "            # 如果比最大概率的类别大，则更新最大概率和类别\n",
    "            if cur_prob > best_prob:\n",
    "                best_prob = cur_prob\n",
    "                best_label = y_i\n",
    "        return best_label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "条件概率P(X = sepal length (cm)|y = 0)的高斯分布密度函数的参数 u = 5.005999999999999 , σ = 0.348946987377739\n",
      "条件概率P(X = sepal width (cm)|y = 0)的高斯分布密度函数的参数 u = 3.428000000000001 , σ = 0.3752545802518604\n",
      "条件概率P(X = sepal length (cm)|y = 1)的高斯分布密度函数的参数 u = 5.936 , σ = 0.5109833656783752\n",
      "条件概率P(X = sepal width (cm)|y = 1)的高斯分布密度函数的参数 u = 2.7700000000000005 , σ = 0.31064449134018135\n",
      "条件概率P(X = sepal length (cm)|y = 2)的高斯分布密度函数的参数 u = 6.587999999999998 , σ = 0.6294886813914925\n",
      "条件概率P(X = sepal width (cm)|y = 2)的高斯分布密度函数的参数 u = 2.9739999999999998 , σ = 0.319255383666431\n",
      "===============准备计算各个类别的后验概率P(y=yi|X=xi)==============\n",
      "\n",
      "先验概率P(y=0的值为0.3333333333333333)\n",
      "条件概率P(X = sepal length (cm)|y = 0)的值为0.00011958039915919892\n",
      "条件概率P(X = sepal width (cm)|y = 0)的值为1.0437344201467702\n",
      "类别标签为0的概率值为4.160339285911526e-05\n",
      "\n",
      "先验概率P(y=1的值为0.3333333333333333)\n",
      "条件概率P(X = sepal length (cm)|y = 1)的值为0.4245791310208984\n",
      "条件概率P(X = sepal width (cm)|y = 1)的值为0.08118926099969548\n",
      "类别标签为1的概率值为0.011490421961159875\n",
      "\n",
      "先验概率P(y=2的值为0.3333333333333333)\n",
      "条件概率P(X = sepal length (cm)|y = 2)的值为0.627593516937744\n",
      "条件概率P(X = sepal width (cm)|y = 2)的值为0.3216019073699372\n",
      "类别标签为2的概率值为0.06727842403339515\n",
      "\n",
      "=========预测的类别标签为2==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5e7e205cf8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df[\"label\"] = iris.target\n",
    "df = df.iloc[:,[0,1,-1]]\n",
    "clf = GaussianNB()\n",
    "clf.fit(df)\n",
    "target = [6.5,3.5]\n",
    "res = clf.predict(target)\n",
    "print(\"=========预测的类别标签为{}==========\".format(res))\n",
    "\n",
    "'''\n",
    "绘图，直观的观察结果\n",
    "'''\n",
    "df_label1 = df[df.iloc[:,-1]==0]\n",
    "df_label2 = df[df.iloc[:,-1]==1]\n",
    "df_label3 = df[df.iloc[:,-1]==2]\n",
    "plt.scatter(df_label1.iloc[:,0],df_label1.iloc[:,1],label = \"0\")\n",
    "plt.scatter(df_label2.iloc[:,0],df_label2.iloc[:,1],label = \"1\")\n",
    "plt.scatter(df_label3.iloc[:,0],df_label3.iloc[:,1],label = \"2\")\n",
    "plt.xlabel(\"sepal length\")\n",
    "plt.ylabel(\"sepal width\")\n",
    "plt.scatter(target[0],target[1],c = \"red\",marker = \"X\",label = \"test_point\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.27891857e-04 1.45798205e-01 8.53673903e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 调用scikit-learn包里的高斯朴素贝叶斯进行验证\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(df.iloc[:,:-1],df.iloc[:,-1])\n",
    "# 输出scikit-learn包里的模型对于预测点的各个类别的概率\n",
    "# 可以看出类别2基本是类别1的 5.85倍 ， 可见手写的高斯朴素贝叶斯也是对的！！！\n",
    "print(clf.predict_proba([target]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
